root@b0c45cf15098:/llm/cechallenge/llama_v1# torchrun --nproc_per_node 4 example.py --ckpt_dir /llm/model/30B --tokenizer_path /llm/model/30B/tokenizer.model
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
*****************************************
> initializing model parallel with size 4
> initializing ddp with size 1
> initializing pipeline with size 1
522it [00:00, 2668.46it/s]Hellaswag dataset load finish , len: 5041
5041it [00:02, 1706.39it/s]
5041it [00:02, 1720.96it/s]
5041it [00:03, 1629.68it/s]
5041it [00:02, 1720.82it/s]
{0: 40, 1: 40, 2: 40, 3: 40, 4: 40, 5: 40, 6: 40, 7: 40, 8: 40, 9: 40, 10: 40, 11: 40, 12: 40, 13: 40, 14: 40, 15: 40, 16: 40, 17: 40, 18: 40, 19: 40, 20: 40, 21: 40, 22: 40, 23: 40, 24: 40, 25: 40, 26: 40, 27: 40, 28: 40, 29: 40, 30: 40, 31: 40, 32: 40, 33: 40, 34: 40, 35: 40, 36: 40, 37: 40, 38: 40, 39: 40, 40: 40, 41: 40, 42: 40, 43: 40, 44: 40, 45: 40, 46: 40, 47: 40, 48: 40, 49: 40, 50: 40, 51: 40, 52: 40, 53: 40, 54: 40, 55: 40, 56: 40, 57: 40, 58: 40, 59: 40, 60: 40, 61: 40, 62: 40, 63: 40, 64: 40, 65: 40, 66: 40, 67: 40, 68: 40, 69: 40, 70: 40, 71: 40, 72: 40, 73: 40, 74: 40, 75: 40, 76: 40, 77: 40, 78: 40, 79: 40, 80: 40, 81: 40, 82: 40, 83: 40, 84: 40, 85: 40, 86: 40, 87: 40, 88: 40, 89: 40, 90: 40, 91: 40, 92: 40, 93: 40, 94: 40, 95: 40, 96: 40, 97: 40, 98: 40, 99: 40, 100: 40, 101: 40, 102: 40, 103: 40, 104: 40, 105: 40, 106: 40, 107: 80, 108: 75, 109: 75, 110: 75, 111: 75, 112: 75, 113: 75, 114: 75, 115: 75, 116: 75, 117: 75, 118: 75, 119: 75, 120: 75, 121: 75, 122: 75, 123: 75, 124: 75, 125: 75, 126: 75, 127: 75, 128: 75, 129: 75, 130: 75, 131: 75, 132: 75, 133: 75, 134: 75, 135: 80, 136: 80, 137: 80, 138: 80, 139: 80, 140: 80, 141: 80, 142: 80, 143: 80, 144: 80, 145: 80, 146: 80, 147: 80, 148: 80, 149: 80, 150: 80, 151: 80, 152: 80, 153: 80, 154: 80, 155: 80, 156: 80, 157: 80, 158: 80, 159: 80, 160: 80, 161: 80, 162: 80, 163: 80, 164: 80, 165: 80, 166: 80, 167: 80, 168: 80, 169: 80, 170: 80, 171: 80, 172: 80, 173: 80, 174: 80, 175: 80, 176: 80, 177: 80, 178: 80, 179: 80, 180: 80, 181: 80, 182: 80, 183: 80, 184: 80, 185: 80, 186: 80, 187: 80, 188: 80, 189: 80, 190: 80, 191: 80, 192: 80, 193: 80, 194: 80, 195: 80, 196: 80, 197: 80, 198: 80, 199: 80, 200: 80, 201: 80, 202: 80, 203: 80, 204: 80, 205: 80, 206: 80, 207: 80, 208: 80, 209: 80, 210: 80, 211: 80, 212: 80, 213: 80, 214: 80, 215: 80, 216: 80, 217: 80, 218: 80, 219: 80, 220: 80, 221: 80, 222: 80, 223: 80, 224: 80, 225: 80, 226: 80, 227: 80, 228: 80, 229: 80, 230: 120, 231: 120, 232: 120, 233: 120, 234: 120, 235: 45, 236: 120, 237: 120, 238: 120, 239: 120, 240: 120, 241: 120, 242: 120, 243: 120, 244: 120, 245: 120, 246: 120, 247: 120, 248: 120, 249: 120, 250: 120, 251: 120, 252: 120, 253: 120, 254: 120, 255: 120, 256: 120, 257: 120, 258: 120, 259: 120, 260: 120, 261: 120, 262: 120, 263: 120, 264: 120, 265: 120, 266: 120, 267: 150, 268: 56, 269: 40, 270: 40, 271: 40, 272: 40, 273: 40, 274: 40, 275: 40, 276: 40, 277: 40, 278: 40, 279: 40, 280: 40, 281: 40, 282: 40, 283: 40, 284: 40, 285: 40, 286: 40, 287: 40, 288: 40, 289: 40, 290: 40, 291: 40, 292: 40, 293: 40, 294: 40, 295: 40, 296: 40, 297: 40, 298: 40, 299: 40, 300: 40, 301: 40, 302: 40, 303: 40, 304: 40, 305: 40, 306: 40, 307: 40, 308: 40, 309: 8}
pickle: 20164
after splitting: 20164 309
Loading
  0%|                                                                                                                                                              | 0/310 [00:00<?, ?it/s]Loaded in 14.42 seconds
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [17:23<00:00,  3.37s/it]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [17:22<00:00,  3.36s/it]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [17:22<00:00,  3.36s/it]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 310/310 [17:23<00:00,  3.37s/it]
Accuracy: 0.6288434834358262
Normalized Accuracy: 0.8192818885141837
Total_time    : 1067.449341058731 s
Preprocessing : 6.42132306098938 s
Model_loading : 14.800158739089966 s
Evaluation    : 1042.0702545642853 s
Acc_Cal       : 0.953662633895874 s
Others        : 3.203942060470581 s